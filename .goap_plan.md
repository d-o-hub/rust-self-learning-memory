# GOAP Plan: Unit Test Optimization

## Executive Summary

**Goal:** Optimize unit tests to reduce count, improve performance, and apply BDD principles

**Current State:** 182 tests, 6,928 LOC, ~40% redundancy
**Target State:** ~110 tests, <4,500 LOC, 100% BDD compliance, 30%+ faster execution

**Strategy:** Hybrid execution (Sequential analysis → Parallel implementation → Sequential validation)

---

## Phase 1: ANALYZE - Task Analysis

### Primary Goal
Reduce test count by 40%, improve performance by 30%, achieve 100% BDD compliance

### Constraints
- **Must maintain >90% code coverage** (current NFR4 requirement)
- **Zero breaking changes** to public APIs
- **All tests must pass** before and after optimization
- **Time:** Normal priority (2-3 hour execution window)

### Complexity Level
**Complex** - Requires:
- Multi-file refactoring across 4 crates
- Coordination of multiple optimization strategies
- Quality validation at multiple checkpoints

### Quality Requirements
- **Testing:** All optimized tests must pass
- **Standards:** AGENTS.md compliance, Rust best practices, BDD principles
- **Performance:** 30%+ execution time reduction
- **Documentation:** Clear test names following BDD conventions

---

## Phase 2: DECOMPOSE - Task Breakdown

### Main Goal
**Optimize unit tests for reduced count, better performance, and BDD compliance**

### Sub-Goals (Priority Order)

#### P0: Create Shared Test Infrastructure
- **Success Criteria:** Single test_helpers module, no duplicated utilities
- **Dependencies:** None
- **Complexity:** Medium
- **Impact:** Enables all other optimizations

#### P1: Consolidate Redundant Tests
- **Success Criteria:** 40% reduction in test count, same coverage
- **Dependencies:** P0 (test helpers)
- **Complexity:** High
- **Impact:** Major LOC reduction

#### P2: Apply BDD Refactoring
- **Success Criteria:** 100% tests follow Given-When-Then, behavior-focused names
- **Dependencies:** P1 (consolidated tests)
- **Complexity:** Medium
- **Impact:** Improved maintainability and clarity

#### P3: Optimize Performance Tests
- **Success Criteria:** Remove/reduce large data tests, faster execution
- **Dependencies:** P1, P2
- **Complexity:** Low
- **Impact:** 30%+ speed improvement

### Atomic Tasks

**Sub-Goal P0: Create Shared Test Infrastructure**
- Task P0.1: Create `memory-core/tests/common/mod.rs` test helpers module (Agent: refactorer)
- Task P0.2: Extract shared fixtures (TaskContext, Episode builders) (Agent: refactorer)
- Task P0.3: Create parameterized test macros (Agent: feature-implementer)
- Task P0.4: Update all tests to use shared helpers (Agent: refactorer)

**Sub-Goal P1: Consolidate Redundant Tests**
- Task P1.1: Merge input_validation tests into parameterized tests (Agent: refactorer)
- Task P1.2: Consolidate pattern extraction tests across files (Agent: refactorer)
- Task P1.3: Merge compliance + regression into behavior-focused tests (Agent: refactorer)
- Task P1.4: Remove duplicate integration tests (Agent: refactorer)

**Sub-Goal P2: Apply BDD Refactoring**
- Task P2.1: Rename tests to behavior-focused names (should_*) (Agent: refactorer)
- Task P2.2: Restructure tests with Given-When-Then comments (Agent: refactorer)
- Task P2.3: Split multi-assertion tests into focused tests (Agent: refactorer)
- Task P2.4: Add descriptive test documentation (Agent: refactorer)

**Sub-Goal P3: Optimize Performance Tests**
- Task P3.1: Reduce large data tests (1MB → 10KB representative samples) (Agent: refactorer)
- Task P3.2: Remove/archive ignored long-running tests (Agent: refactorer)
- Task P3.3: Use test fixtures instead of recreating data (Agent: refactorer)

### Dependency Graph
```
P0.1 (create helpers) → P0.2 (extract fixtures) → P0.3 (macros) → P0.4 (migrate)
                                                                      ↓
P1.1 (input_validation) → P1.2 (patterns) → P1.3 (compliance) → P1.4 (integration)
                                                                      ↓
P2.1 (rename) → P2.2 (restructure) → P2.3 (split) → P2.4 (document)
                                                          ↓
P3.1 (reduce data) → P3.2 (remove ignored) → P3.3 (fixtures)
```

---

## Phase 3: STRATEGIZE - Execution Strategy Selection

### Strategy: **HYBRID**

**Rationale:**
- **Sequential Phase 1** (P0): Must create infrastructure first
- **Parallel Phase 2** (P1.1-P1.4): Independent file consolidations
- **Sequential Phase 3** (P2): BDD refactoring depends on consolidated tests
- **Parallel Phase 4** (P3): Performance optimizations are independent

### Expected Performance
- **Speedup:** 2-3x over pure sequential
- **Complexity:** High (requires coordination)
- **Risk:** Medium (parallel work must not conflict)

---

## Phase 4: COORDINATE - Agent Assignment

### Agent Capability Mapping

| Task Group | Agent Type | Rationale |
|------------|------------|-----------|
| P0 (Infrastructure) | refactorer | Code structure improvements |
| P1 (Consolidation) | refactorer | Systematic code reduction |
| P2 (BDD Refactoring) | quality-unit-testing skill | BDD expertise |
| P3 (Performance) | refactorer | Code optimization |
| Validation | test-runner | Execute and verify |

### Workload Distribution
- **Phase 1:** 1 refactorer agent (sequential)
- **Phase 2:** 1 refactorer agent (handles all file consolidations)
- **Phase 3:** 1 quality-unit-testing skill (BDD transformation)
- **Phase 4:** 1 refactorer agent (performance tuning)
- **Validation:** 1 test-runner agent

---

## Phase 5: EXECUTE - Execution Plan

### Phase 1: Infrastructure (Sequential)
**Duration:** ~20 minutes
**Agent:** refactorer

**Tasks:**
1. Create `memory-core/tests/common/mod.rs` with shared test utilities
2. Extract fixture builders (EpisodeBuilder, ContextBuilder, StepBuilder)
3. Create parameterized test macro for input validation
4. Migrate learning_cycle.rs to use new helpers

**Quality Gate:** ✓ All existing tests still pass with new helpers

---

### Phase 2: Consolidation (Sequential - Single File Focus)
**Duration:** ~40 minutes
**Agent:** refactorer

**Tasks:**
1. **input_validation.rs:** Convert 13 tests → 4 parameterized tests
   - Large inputs, special chars, null bytes → single parameterized test
   - Excessive metadata, many steps → boundary tests
   - Remove redundant tests (concurrent_step_logging duplicates learning_cycle)

2. **pattern_accuracy.rs:** Reduce 8 tests → 3 focused tests
   - Merge ground truth tests into single data-driven test
   - Consolidate metrics calculation with pattern extraction

3. **compliance.rs + regression.rs:** Merge into behavior tests
   - Combine FR1-FR5 compliance into behavior-focused tests
   - Remove duplicate episode creation/retrieval tests

4. **integration tests:** Deduplicate across crates
   - Keep one authoritative integration test per crate
   - Remove overlapping tests

**Quality Gate:** ✓ Tests pass, coverage maintained, 40% reduction achieved

---

### Phase 3: BDD Refactoring (Sequential)
**Duration:** ~30 minutes
**Agent:** quality-unit-testing skill

**Tasks:**
1. Rename all tests to BDD convention:
   - `test_handles_large_episode_description` → `should_store_large_episodes_without_data_loss`
   - `verify_fr1_episode_creation` → `should_create_episodes_with_unique_ids_and_timestamps`

2. Add Given-When-Then structure:
   ```rust
   #[tokio::test]
   async fn should_extract_patterns_from_completed_episodes() {
       // Given: A memory system with a completed episode containing clear patterns
       let memory = TestMemory::with_pattern_episode();

       // When: We retrieve patterns for the same context
       let patterns = memory.retrieve_relevant_patterns(&context, 10).await;

       // Then: The system should return extracted patterns
       assert!(!patterns.is_empty());
       assert!(patterns.iter().any(|p| matches!(p, Pattern::ErrorRecovery { .. })));
   }
   ```

3. Split multi-assertion tests:
   - pattern_accuracy tests with 8+ assertions → separate focused tests
   - compliance tests validating multiple behaviors → one test per behavior

4. Add module-level documentation explaining test strategy

**Quality Gate:** ✓ 100% BDD compliance, tests are behavior-focused

---

### Phase 4: Performance Optimization (Sequential)
**Duration:** ~20 minutes
**Agent:** refactorer

**Tasks:**
1. Reduce large data tests:
   - 1MB description → 10KB (still validates handling)
   - 1000 metadata fields → 100 (boundary test)
   - 500 steps → 50 (representative sample)

2. Remove/archive ignored tests:
   - `#[ignore] verify_nfr1_retrieval_latency_10k_episodes` → Move to benchmarks
   - `#[ignore] verify_nfr2_storage_capacity_10k` → Move to stress tests

3. Use test fixtures:
   - Pre-built episode data loaded once per test module
   - Shared memory instances with `lazy_static!` or `OnceCell`

**Quality Gate:** ✓ 30%+ execution time reduction, tests still validate behavior

---

## Phase 6: SYNTHESIZE - Validation & Results

### Validation Steps

1. **Unit Tests:** `cargo test --all`
2. **Coverage:** `cargo llvm-cov test --all` (must be >90%)
3. **Lint:** `cargo clippy --all -- -D warnings`
4. **Format:** `cargo fmt --all -- --check`
5. **Performance:** Measure test execution time before/after

### Success Criteria

- [ ] All tests pass
- [ ] Coverage remains >90%
- [ ] Test count reduced by 40% (182 → ~110 tests)
- [ ] LOC reduced by 35% (6,928 → <4,500 LOC)
- [ ] Execution time reduced by 30%+
- [ ] 100% tests follow BDD naming (should_*)
- [ ] 100% tests have Given-When-Then structure
- [ ] No code duplication in test helpers
- [ ] All quality gates passed

### Expected Deliverables

1. **Optimized test files:**
   - `memory-core/tests/common/mod.rs` (new shared helpers)
   - Refactored test files with BDD structure
   - Consolidated test suites

2. **Documentation:**
   - Updated test strategy in TESTING.md
   - Test helper documentation
   - BDD examples

3. **Metrics Report:**
   - Before/after test counts
   - Before/after execution times
   - Coverage comparison

### Contingency Plans

**If coverage drops below 90%:**
1. Identify uncovered code paths
2. Add focused tests for gaps
3. Re-run coverage validation

**If tests fail after consolidation:**
1. Isolate failing test
2. Compare behavior with original
3. Fix logic or restore original test

**If execution time doesn't improve 30%:**
1. Profile test execution
2. Identify bottlenecks
3. Apply additional optimizations (mocking, test parallelization)

---

## Phase 7: LESSONS LEARNED

### What Worked Well
- (To be filled after execution)

### What to Improve
- (To be filled after execution)

### Reusable Patterns
- (To be filled after execution)

---

## Execution Timeline

| Phase | Duration | Agent | Status |
|-------|----------|-------|--------|
| P1: Infrastructure | 20 min | refactorer | ⏳ Pending |
| P2: Consolidation | 40 min | refactorer | ⏳ Pending |
| P3: BDD Refactoring | 30 min | quality-unit-testing | ⏳ Pending |
| P4: Performance | 20 min | refactorer | ⏳ Pending |
| Validation | 15 min | test-runner | ⏳ Pending |
| **Total** | **~2 hours** | | |

---

**Plan Status:** Ready for Execution
**Next Action:** Begin Phase 1 - Infrastructure Creation
